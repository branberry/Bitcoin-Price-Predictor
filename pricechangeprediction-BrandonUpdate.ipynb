{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function retrieves the previous 4 days given a single day for input from the .csv file.\n",
    "def getEvalData(nparray,date,predict_delta):\n",
    "    res = [[]]\n",
    "    idx = np.argwhere(nparray==date)[0][0] - 5\n",
    "    # if the given date does not have 5 previous values...\n",
    "    if idx < 4 or idx + 7 > nparray.shape[0]:\n",
    "        return\n",
    "    else:\n",
    "        for i in range(5):\n",
    "            res[0].append(nparray[i+idx][1])\n",
    "        predict_day = nparray[i+idx+predict_delta][1]\n",
    "        predict_day_percent = (predict_day - res[0][4])/predict_day\n",
    "        res.append(predict_day_percent)\n",
    "        res.append(predict_day)\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "518\n",
      "439\n",
      "[[ 134.21  144.54  139.    116.99  105.21]\n",
      " [ 144.54  139.    116.99  105.21   97.75]\n",
      " [ 139.    116.99  105.21   97.75  112.5 ]\n",
      " ...\n",
      " [2608.56 2518.66 2571.34 2518.44 2372.56]\n",
      " [2518.66 2571.34 2518.44 2372.56 2337.79]\n",
      " [2571.34 2518.44 2372.56 2337.79 2398.84]]\n"
     ]
    }
   ],
   "source": [
    "# Trying to convert the input data, which starts off as dataframeX, must take 5 days and then transpose it\n",
    "# and then convert it into a numpy array\n",
    "\n",
    "rawdata = pd.read_csv('data/bitcoin.csv',usecols=[8])\n",
    "days = 5                                                      # Number of days we are looking at\n",
    "predict_delta = 7                                             # Number of days we are predicting into the future \n",
    "number_of_items = rawdata.shape[0] - (predict_delta + days)   # number of tests\n",
    "# size of our test \n",
    "test_size = number_of_items - 733\n",
    "\n",
    "# five day blocks in a list\n",
    "Xtrain = []    \n",
    "# the values of the day we are trying to predict\n",
    "Ytrain = []                                                   \n",
    "\n",
    "\n",
    "\n",
    "# Splits the array of closing prices up into multiple arrays, each holding five days worth of prices\n",
    "# then transposes each array and finally appends them onto one large matrix\n",
    "countup = 0\n",
    "counteven = 0\n",
    "countdown = 0\n",
    "for i in range(number_of_items - 200): \n",
    "    # finding the predict day\n",
    "    predict = rawdata.head(days + i + predict_delta).tail(1).as_matrix().transpose().tolist()[0][0]\n",
    "    last_day = rawdata.head(days + i).tail(1).as_matrix().transpose().tolist()[0][0]\n",
    "    # Converting and adding data to arrays\n",
    "    res = rawdata.head(days + i).tail(days).as_matrix().transpose().tolist()[0]\n",
    "    Xtrain.append(res)\n",
    "    y_val = (predict - last_day)/predict\n",
    "    if y_val > .03:\n",
    "        countup = countup + 1\n",
    "        Ytrain.append(np.array([1, 0, 0]))\n",
    "        \n",
    "    elif y_val > -.03 and y_val < .03:\n",
    "        counteven = counteven + 1\n",
    "        Ytrain.append(np.array([0, 1, 0]))\n",
    "        \n",
    "    else:\n",
    "        countdown = countdown + 1\n",
    "        Ytrain.append(np.array([0, 0, 1]))\n",
    "        \n",
    "    \n",
    "print(countup)\n",
    "print(counteven)\n",
    "print(countdown)\n",
    "# converts python arrays into numpy arrays\n",
    "Xtrain = np.array(Xtrain)\n",
    "Ytrain = np.array(Ytrain)\n",
    "print(Xtrain)\n",
    "\n",
    "#print(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-166ca220fb32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# putting y-values into the correct bucket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredictE\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlast_dayE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpredictE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m.03\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mcountup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountup\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# number of evalutaion data points\n",
    "eval_size = number_of_items - 200\n",
    "\n",
    "# evaluation input data\n",
    "XEvaluation = []\n",
    "# evaluation output data\n",
    "YEvaluation = []\n",
    "\n",
    "# appending evaluation data to appropriate arrays\n",
    "for i in range(eval_size):\n",
    "    # finding the day we want to predict a week out\n",
    "    predict = rawdata.head(days + i + test_size + predict_delta).tail(1).as_matrix().transpose().tolist()[0][0]\n",
    "    \n",
    "    # finding the last day out of the 5 we are using as input to later calculate the percent difference \n",
    "    # of the change.  The percentage change is not the absolute value as we want to calculate negative percentages as well\n",
    "    last_day = rawdata.head(days + i + test_size).tail(1).as_matrix().transpose().tolist()[0][0]\n",
    "    \n",
    "    # result after running the AvgPrevious function on the 5 days used as input\n",
    "    res = rawdata.head(days + i + test_size).tail(days).as_matrix().transpose().tolist()[0]\n",
    "    XEvaluation.append(res)\n",
    "    \n",
    "    # putting y-values into the correct bucket\n",
    "    #y_val = (predict - last_day)/predict\n",
    "   # if y_val > .03:\n",
    "    #    countup = countup + 1\n",
    "   #     YEvaluation.append(np.array([1, 0, 0]))\n",
    "        \n",
    "   # elif y_val > -.03 and y_val < .03:\n",
    "    #    counteven = counteven + 1\n",
    "   #     YEvaluation.append(np.array([0, 1, 0]))\n",
    "        \n",
    "    #else:\n",
    "        countdown = countdown + 1\n",
    "        YEvaluation.append(np.array([0, 0, 1]))\n",
    "    \n",
    "XEvaluation = np.array(XEvaluation)\n",
    "YEvaluation = np.array(YEvaluation)\n",
    "\n",
    "print(XEvaluation)\n",
    "print(YEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1533/1533 [==============================] - 1s 603us/step - loss: 1.0974 - acc: 0.3627\n",
      "Epoch 2/10\n",
      "1533/1533 [==============================] - 0s 132us/step - loss: 1.0948 - acc: 0.3633\n",
      "Epoch 3/10\n",
      "1533/1533 [==============================] - 0s 138us/step - loss: 1.0930 - acc: 0.3816\n",
      "Epoch 4/10\n",
      "1533/1533 [==============================] - 0s 181us/step - loss: 1.0951 - acc: 0.3673\n",
      "Epoch 5/10\n",
      "1533/1533 [==============================] - 0s 146us/step - loss: 1.0917 - acc: 0.3894\n",
      "Epoch 6/10\n",
      "1533/1533 [==============================] - 0s 129us/step - loss: 1.0886 - acc: 0.3914\n",
      "Epoch 7/10\n",
      "1533/1533 [==============================] - 0s 144us/step - loss: 1.0875 - acc: 0.3999\n",
      "Epoch 8/10\n",
      "1533/1533 [==============================] - 0s 151us/step - loss: 1.0867 - acc: 0.3875\n",
      "Epoch 9/10\n",
      "1533/1533 [==============================] - 0s 136us/step - loss: 1.0897 - acc: 0.4031\n",
      "Epoch 10/10\n",
      "1533/1533 [==============================] - 0s 133us/step - loss: 1.0845 - acc: 0.3914\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(48,input_dim=5))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(1.0))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(Xtrain, Ytrain, epochs=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5155729  0.22694626 0.2574809 ]]\n"
     ]
    }
   ],
   "source": [
    "Test = [8070.8, 8891.21, 8516.24, 9477.84, 10016.49]\n",
    "XVal = np.array([Test])\n",
    "r = model.predict(XVal)\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dropout_19 to have shape (3,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ecc59347b5c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXEvaluation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYEvaluation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The evaluation loss is: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1002\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                    steps=steps)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1766\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1769\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32mb:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dropout_19 to have shape (3,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(XEvaluation,YEvaluation,batch_size=100, verbose=1)\n",
    "test_loss = score[0]\n",
    "print(\"The evaluation loss is: \" + str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 48)                288       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 24)                1176      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 3,891\n",
      "Trainable params: 3,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5155729  0.22694626 0.2574809 ]]\n",
      "[[11490.5, 11188.6, 11474.9, 11607.4, 12899.2], -0.12748345818000645, 11440.7]\n"
     ]
    }
   ],
   "source": [
    "rawdata = pd.read_csv('data/bitcoin.csv',usecols=[3,8])\n",
    "data = rawdata.as_matrix()\n",
    "#print(np.argwhere(data=='2016-10-08')[0][0])\n",
    "\n",
    "res = getEvalData(data,'2018-01-21',predict_delta)\n",
    "\n",
    "evaluation = np.array([res[0]])\n",
    "print(model.predict(evaluation))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_working.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
